{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn import model_selection\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "iris=datasets.load_iris();\n",
    "x=iris.data\n",
    "y=iris.target\n",
    "x_train,x_test,y_train,y_test=model_selection.train_test_split(x,y,test_size=0.5,random_state=0)\n",
    "\n",
    "features=np.arange(1,5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_cal(class_values,dictionary,total_length):\n",
    "    ans=0\n",
    "    for current_class in class_values:\n",
    "        a=dictionary[current_class]/total_length\n",
    "        ans=ans+a*(np.log2(a))\n",
    "    if(ans==0):\n",
    "        return 0\n",
    "    return(-1*ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_gain_cal(x,y,feature,current_entropy):\n",
    "    my_column=x[:,feature-1]\n",
    "    np.sort(my_column)\n",
    "    my_midpoint_array=[]\n",
    "    for i in range(len(my_column)-1):\n",
    "        a=(my_column[i]+my_column[i+1])/2\n",
    "        my_midpoint_array.append(a)\n",
    "        \n",
    "    ans=0\n",
    "    #split_info=0\n",
    "    total=len(y)\n",
    "    \n",
    "    temp_info_gain=0\n",
    "    max_info_gain=0\n",
    "    final_divider=0\n",
    "    \n",
    "    for divider in my_midpoint_array:\n",
    "        my_true_false_row1=x[:,feature-1]>divider\n",
    "        my_true_false_row2=x[:,feature-1]<=divider\n",
    "        \n",
    "        my_y_greater_than=y[my_true_false_row1]\n",
    "        my_y_smaller_than=y[my_true_false_row2]\n",
    "        \n",
    "        #calculating entropy of first node_greater than node\n",
    "        class_values=set(my_y_greater_than)\n",
    "        dictionary1={}\n",
    "        for current_class in class_values:\n",
    "            current_class_rows=(my_y_greater_than==current_class)\n",
    "            y_current_class=my_y_greater_than[current_class_rows]\n",
    "            dictionary1[current_class]=len(y_current_class)\n",
    "            \n",
    "        current_entropy1=entropy_cal(class_values,dictionary1,len(my_y_greater_than))\n",
    "        \n",
    "        c=len(my_y_greater_than)/total\n",
    "        #split_info=split_info+(-1*(c)*np.log(c))\n",
    "        ans=ans+c*current_entropy1\n",
    "        \n",
    "        #calculating entropy of first node_smaller than node\n",
    "        \n",
    "        class_values=set(my_y_smaller_than)\n",
    "        dictionary2={}\n",
    "        for current_class in class_values:\n",
    "            current_class_rows=(my_y_smaller_than==current_class)\n",
    "            y_current_class=my_y_smaller_than[current_class_rows]\n",
    "            dictionary2[current_class]=len(y_current_class)\n",
    "            \n",
    "        current_entropy1=entropy_cal(class_values,dictionary2,len(my_y_smaller_than))\n",
    "        \n",
    "        c=len(my_y_smaller_than)/total\n",
    "        #split_info=split_info+(-1*(c)*np.log(c))\n",
    "        ans=ans+c*current_entropy1\n",
    "        \n",
    "        temp_info_gain=(current_entropy-ans)\n",
    "        \n",
    "        if(temp_info_gain >max_info_gain):\n",
    "            max_info_gain=temp_info_gain\n",
    "            final_divider=divider\n",
    "\n",
    "    return max_info_gain,final_divider "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__ (self,level,dictionary,entropy,divider,divider_feature,is_leaf):\n",
    "        self.level=level\n",
    "        self.dictionary=dictionary\n",
    "        self.entropy=entropy\n",
    "        self.divider=divider\n",
    "        self.is_leaf=is_leaf\n",
    "        self.divider_feature=divider_feature\n",
    "        self.left=None\n",
    "        self.right=None\n",
    "    def print(self):\n",
    "        if self.left:\n",
    "            self.left.print()\n",
    "        print(\"hi i am level\",self.level)\n",
    "        print()\n",
    "        if self.right:\n",
    "            self.right.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_training(x,y,features,level):\n",
    "    class_values=set(y)\n",
    "    dictionary={}\n",
    "    #print()\n",
    "    #print(\"level \",level)\n",
    "    \n",
    "    for current_class in class_values:\n",
    "        current_class_rows=(y==current_class)\n",
    "        y_current_class=y[current_class_rows]\n",
    "        dictionary[current_class]=len(y_current_class)\n",
    "        #print(\"count of\",current_class,\"=\",dictionary[current_class])\n",
    "    \n",
    "    current_entropy=entropy_cal(class_values,dictionary,len(y))\n",
    "    #print(\"Current Entropy is =\",current_entropy)\n",
    "    \n",
    "    \n",
    "    node=Node(level,dictionary,current_entropy,math.inf,math.inf,False)\n",
    "    \n",
    "    if(len(class_values)==1):\n",
    "        #print(\"Reached leaf Node\")\n",
    "        node.is_leaf=True\n",
    "        return node\n",
    "    \n",
    "    elif(len(features)==0):\n",
    "        #print(\"Reached leaf Node\")\n",
    "        node.is_leaf=True\n",
    "        return node\n",
    "    \n",
    "    max_info_gain=-1\n",
    "    final_feature=0\n",
    "    divider=0\n",
    "    for i in features:\n",
    "        temp_info_gain,temp_divider=info_gain_cal(x,y,i,current_entropy)\n",
    "        if(temp_info_gain > max_info_gain):\n",
    "            max_info_gain=temp_info_gain\n",
    "            final_feature=i\n",
    "            divider=temp_divider\n",
    "    \n",
    "    #print(\"Splitting on feature\",final_feature,\"with informationgain \",max_info_gain)\n",
    "    node.divider=divider\n",
    "    node.divider_feature=final_feature-1\n",
    "    \n",
    "    i=np.where(features==final_feature)\n",
    "    if(len(i[0])):\n",
    "        i=int(i[0])\n",
    "        features=np.delete(features,i) \n",
    "        \n",
    "    my_true_false_row1=(x[:,final_feature-1]>divider)\n",
    "    my_true_false_row2=(x[:,final_feature-1]<=divider)\n",
    "        \n",
    "    my_y_greater_than=y[my_true_false_row1]\n",
    "    my_y_smaller_than=y[my_true_false_row2]\n",
    "    \n",
    "    my_x_greater_than=x[my_true_false_row1]\n",
    "    my_x_smaller_than=x[my_true_false_row2]\n",
    "    \n",
    "    node.left=decision_tree_training(my_x_greater_than,my_y_greater_than,features,level+1)\n",
    "    node.right=decision_tree_training(my_x_smaller_than,my_y_smaller_than,features,level+1)\n",
    "    \n",
    "    return node\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_point(root,x):\n",
    "    \n",
    "    if(root.is_leaf==True):\n",
    "        dictionary=root.dictionary\n",
    "        classes=dictionary.keys()\n",
    "        ans=0\n",
    "        my_count=0\n",
    "        for class_ in classes:\n",
    "            if(dictionary[class_]>my_count):\n",
    "                my_count=dictionary[class_]\n",
    "                ans=class_\n",
    "        return ans\n",
    "    \n",
    "    feature_index=root.divider_feature\n",
    "    feature_value=x[feature_index]\n",
    "    ans=0\n",
    "    \n",
    "    if(feature_value >root.divider):\n",
    "        ans=predict_single_point(root.left,x)\n",
    "    else:\n",
    "        ans=predict_single_point(root.right,x)\n",
    "    \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(root,x_test):\n",
    "    y_pred=[]\n",
    "    for x in x_test:\n",
    "        x_class=predict_single_point(root,x)\n",
    "        y_pred.append(x_class)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1, 0, 2, 0, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1, 0, 0, 2, 0, 0, 1, 1, 0, 2, 1, 0, 2, 2, 1, 0, 1, 1, 1, 2, 0, 2, 0, 0, 1, 2, 2, 1, 2, 1, 2, 1, 1, 2, 1, 2, 2, 1, 2, 1, 0, 2, 1, 1, 1, 1, 2, 0, 0, 2, 1, 0, 0, 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "root=decision_tree_training(x_train,y_train,features,0)\n",
    "y_prediction=predict(root,x_test)\n",
    "\n",
    "print(y_prediction)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        21\n",
      "          1       0.91      1.00      0.95        30\n",
      "          2       1.00      0.88      0.93        24\n",
      "\n",
      "avg / total       0.96      0.96      0.96        75\n",
      "\n",
      "[[21  0  0]\n",
      " [ 0 30  0]\n",
      " [ 0  3 21]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "print(classification_report(y_test,y_prediction))\n",
    "print(confusion_matrix(y_test,y_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
